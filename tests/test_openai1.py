#!/usr/bin/env python3
"""
OpenAI å¯¹è¯å®¢æˆ·ç«¯è„šæœ¬
åŠŸèƒ½ï¼š
1. æ”¯æŒå†å²è®°å½•ç®¡ç†çš„å¯¹è¯
2. ç»Ÿè®¡æ¯æ¬¡è¯·æ±‚åˆ°å“åº”çš„æ—¶é—´
3. é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
4. Tokenä½¿ç”¨é‡ç»Ÿè®¡
5. å®Œæ•´çš„æ—¥å¿—è®°å½•

ä½œè€…ï¼šAI Assistant
åˆ›å»ºæ—¶é—´ï¼š2024
"""

import os
import json
import time
import asyncio
from datetime import datetime
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, asdict
import logging
from pathlib import Path

import openai
from openai import AsyncOpenAI
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
import tiktoken


@dataclass
class ChatMessage:
    """èŠå¤©æ¶ˆæ¯æ•°æ®ç±»"""
    role: str  # "user", "assistant", "system"
    content: str
    timestamp: float
    token_count: int = 0


@dataclass
class RequestStats:
    """è¯·æ±‚ç»Ÿè®¡æ•°æ®ç±»"""
    request_time: float
    response_time: float
    duration: float
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int
    model: str
    success: bool
    error_message: Optional[str] = None


class ChatHistoryManager:
    """èŠå¤©å†å²è®°å½•ç®¡ç†å™¨"""
    
    def __init__(self, history_file: str = "chat_history.json"):
        """
        åˆå§‹åŒ–å†å²è®°å½•ç®¡ç†å™¨
        
        Args:
            history_file: å†å²è®°å½•æ–‡ä»¶è·¯å¾„
        """
        self.history_file = Path(history_file)
        self.messages: List[ChatMessage] = []
        self.load_history()
    
    def add_message(self, role: str, content: str, token_count: int = 0) -> None:
        """
        æ·»åŠ æ¶ˆæ¯åˆ°å†å²è®°å½•
        
        Args:
            role: æ¶ˆæ¯è§’è‰²
            content: æ¶ˆæ¯å†…å®¹
            token_count: Tokenæ•°é‡
        """
        message = ChatMessage(
            role=role,
            content=content,
            timestamp=time.time(),
            token_count=token_count
        )
        self.messages.append(message)
        self.save_history()
    
    def get_messages(self, limit: Optional[int] = None) -> List[Dict[str, str]]:
        """
        è·å–å†å²æ¶ˆæ¯ï¼Œæ ¼å¼åŒ–ä¸ºOpenAI APIæ ¼å¼
        
        Args:
            limit: é™åˆ¶è¿”å›çš„æ¶ˆæ¯æ•°é‡
            
        Returns:
            æ ¼å¼åŒ–çš„æ¶ˆæ¯åˆ—è¡¨
        """
        messages = self.messages[-limit:] if limit else self.messages
        return [{"role": msg.role, "content": msg.content} for msg in messages]
    
    def clear_history(self) -> None:
        """æ¸…ç©ºå†å²è®°å½•"""
        self.messages = []
        self.save_history()
    
    def save_history(self) -> None:
        """ä¿å­˜å†å²è®°å½•åˆ°æ–‡ä»¶"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump([asdict(msg) for msg in self.messages], f, 
                         ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")
    
    def load_history(self) -> None:
        """ä»æ–‡ä»¶åŠ è½½å†å²è®°å½•"""
        try:
            if self.history_file.exists():
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.messages = [ChatMessage(**msg) for msg in data]
                logging.info(f"åŠ è½½äº† {len(self.messages)} æ¡å†å²æ¶ˆæ¯")
        except Exception as e:
            logging.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
            self.messages = []


class TokenCounter:
    """Tokenè®¡æ•°å™¨"""
    
    def __init__(self, model: str = "gpt-4o"):
        """
        åˆå§‹åŒ–Tokenè®¡æ•°å™¨
        
        Args:
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.model = model
        try:
            self.encoding = tiktoken.encoding_for_model(model)
        except KeyError:
            # å¦‚æœæ¨¡å‹ä¸æ”¯æŒï¼Œä½¿ç”¨é»˜è®¤ç¼–ç 
            self.encoding = tiktoken.get_encoding("cl100k_base")
    
    def count_tokens(self, text: str) -> int:
        """
        è®¡ç®—æ–‡æœ¬çš„Tokenæ•°é‡
        
        Args:
            text: è¦è®¡ç®—çš„æ–‡æœ¬
            
        Returns:
            Tokenæ•°é‡
        """
        return len(self.encoding.encode(text))
    
    def count_messages_tokens(self, messages: List[Dict[str, str]]) -> int:
        """
        è®¡ç®—æ¶ˆæ¯åˆ—è¡¨çš„æ€»Tokenæ•°é‡
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            æ€»Tokenæ•°é‡
        """
        total_tokens = 0
        for message in messages:
            # æ¯æ¡æ¶ˆæ¯çš„åŸºç¡€Tokenå¼€é”€
            total_tokens += 4  # æ¯æ¡æ¶ˆæ¯çš„æ ¼å¼å¼€é”€
            for key, value in message.items():
                total_tokens += self.count_tokens(value)
        total_tokens += 2  # å¯¹è¯çš„ç»“æŸToken
        return total_tokens


class OpenAIChatClient:
    """OpenAI èŠå¤©å®¢æˆ·ç«¯"""
    
    def __init__(self, 
                 api_key: Optional[str] = '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'
,
                 base_url: Optional[str] = None,
                 model: str = "gpt-4o",
                 max_history: int = 50,
                 stats_file: str = "request_stats.json"):
        """
        åˆå§‹åŒ–OpenAIèŠå¤©å®¢æˆ·ç«¯
        
        Args:
            api_key: OpenAI APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model: ä½¿ç”¨çš„æ¨¡å‹
            max_history: æœ€å¤§å†å²è®°å½•æ•°é‡
            stats_file: ç»Ÿè®¡æ•°æ®æ–‡ä»¶è·¯å¾„
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.base_url = base_url or os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        self.model = model
        self.max_history = max_history
        self.stats_file = Path(stats_file)
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.history_manager = ChatHistoryManager()
        self.token_counter = TokenCounter(model)
        self.request_stats: List[RequestStats] = []
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # åŠ è½½ç»Ÿè®¡æ•°æ®
        self.load_stats()
    
    def _setup_logging(self) -> None:
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('openai_chat.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((openai.RateLimitError, openai.APITimeoutError))
    )
    async def _make_request(self, messages: List[Dict[str, str]], **kwargs) -> Any:
        """
        å‘é€è¯·æ±‚åˆ°OpenAI APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            APIå“åº”
        """
        return await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            **kwargs
        )
    
    async def chat(self, 
                   user_input: str, 
                   system_prompt: Optional[str] = None,
                   **kwargs) -> str:
        """
        è¿›è¡Œå¯¹è¯
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            system_prompt: ç³»ç»Ÿæç¤ºï¼ˆå¯é€‰ï¼‰
            **kwargs: å…¶ä»–OpenAI APIå‚æ•°
            
        Returns:
            AIå›å¤å†…å®¹
        """
        request_start_time = time.time()
        
        try:
            # å‡†å¤‡æ¶ˆæ¯åˆ—è¡¨
            messages = []
            
            # æ·»åŠ ç³»ç»Ÿæç¤º
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            
            # æ·»åŠ å†å²è®°å½•
            history_messages = self.history_manager.get_messages(self.max_history)
            messages.extend(history_messages)
            
            # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
            messages.append({"role": "user", "content": user_input})
            
            # è®¡ç®—è¾“å…¥Tokenæ•°é‡
            prompt_tokens = self.token_counter.count_messages_tokens(messages)
            user_tokens = self.token_counter.count_tokens(user_input)
            
            self.logger.info(f"å‘é€è¯·æ±‚ - æ¨¡å‹: {self.model}, Prompt Tokens: {prompt_tokens}")
            
            # å‘é€è¯·æ±‚
            response = await self._make_request(messages, **kwargs)
            
            request_end_time = time.time()
            duration = request_end_time - request_start_time
            
            # æå–å“åº”å†…å®¹
            assistant_message = response.choices[0].message.content
            
            # è·å–Tokenä½¿ç”¨ç»Ÿè®¡
            usage = response.usage
            completion_tokens = usage.completion_tokens if usage else 0
            total_tokens = usage.total_tokens if usage else 0
            
            # è®¡ç®—åŠ©æ‰‹å›å¤çš„Tokenæ•°é‡
            assistant_tokens = self.token_counter.count_tokens(assistant_message)
            
            # è®°å½•ç»Ÿè®¡ä¿¡æ¯
            stats = RequestStats(
                request_time=request_start_time,
                response_time=request_end_time,
                duration=duration,
                prompt_tokens=usage.prompt_tokens if usage else prompt_tokens,
                completion_tokens=completion_tokens,
                total_tokens=total_tokens,
                model=self.model,
                success=True
            )
            self.request_stats.append(stats)
            
            # ä¿å­˜åˆ°å†å²è®°å½•
            self.history_manager.add_message("user", user_input, user_tokens)
            self.history_manager.add_message("assistant", assistant_message, assistant_tokens)
            
            # ä¿å­˜ç»Ÿè®¡æ•°æ®
            self.save_stats()
            
            # è®°å½•æˆåŠŸæ—¥å¿—
            self.logger.info(
                f"è¯·æ±‚æˆåŠŸ - è€—æ—¶: {duration:.2f}s, "
                f"Tokens: {usage.prompt_tokens if usage else prompt_tokens}/"
                f"{completion_tokens}/{total_tokens}"
            )
            
            return assistant_message
            
        except Exception as e:
            request_end_time = time.time()
            duration = request_end_time - request_start_time
            
            # è®°å½•é”™è¯¯ç»Ÿè®¡
            error_stats = RequestStats(
                request_time=request_start_time,
                response_time=request_end_time,
                duration=duration,
                prompt_tokens=0,
                completion_tokens=0,
                total_tokens=0,
                model=self.model,
                success=False,
                error_message=str(e)
            )
            self.request_stats.append(error_stats)
            self.save_stats()
            
            self.logger.error(f"è¯·æ±‚å¤±è´¥ - è€—æ—¶: {duration:.2f}s, é”™è¯¯: {e}")
            raise
    
    def get_stats_summary(self) -> Dict[str, Any]:
        """
        è·å–ç»Ÿè®¡æ‘˜è¦
        
        Returns:
            ç»Ÿè®¡æ‘˜è¦å­—å…¸
        """
        if not self.request_stats:
            return {"message": "æš‚æ— ç»Ÿè®¡æ•°æ®"}
        
        successful_requests = [s for s in self.request_stats if s.success]
        failed_requests = [s for s in self.request_stats if not s.success]
        
        total_requests = len(self.request_stats)
        success_rate = len(successful_requests) / total_requests * 100
        
        if successful_requests:
            avg_duration = sum(s.duration for s in successful_requests) / len(successful_requests)
            total_tokens = sum(s.total_tokens for s in successful_requests)
            avg_tokens = total_tokens / len(successful_requests)
        else:
            avg_duration = 0
            total_tokens = 0
            avg_tokens = 0
        
        return {
            "æ€»è¯·æ±‚æ•°": total_requests,
            "æˆåŠŸè¯·æ±‚æ•°": len(successful_requests),
            "å¤±è´¥è¯·æ±‚æ•°": len(failed_requests),
            "æˆåŠŸç‡": f"{success_rate:.1f}%",
            "å¹³å‡å“åº”æ—¶é—´": f"{avg_duration:.2f}ç§’",
            "æ€»Tokenä½¿ç”¨é‡": total_tokens,
            "å¹³å‡Tokenä½¿ç”¨é‡": f"{avg_tokens:.0f}",
            "ä½¿ç”¨æ¨¡å‹": self.model
        }
    
    def save_stats(self) -> None:
        """ä¿å­˜ç»Ÿè®¡æ•°æ®åˆ°æ–‡ä»¶"""
        try:
            with open(self.stats_file, 'w', encoding='utf-8') as f:
                json.dump([asdict(stat) for stat in self.request_stats], f, 
                         ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ä¿å­˜ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
    
    def load_stats(self) -> None:
        """ä»æ–‡ä»¶åŠ è½½ç»Ÿè®¡æ•°æ®"""
        try:
            if self.stats_file.exists():
                with open(self.stats_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.request_stats = [RequestStats(**stat) for stat in data]
                self.logger.info(f"åŠ è½½äº† {len(self.request_stats)} æ¡ç»Ÿè®¡è®°å½•")
        except Exception as e:
            self.logger.error(f"åŠ è½½ç»Ÿè®¡æ•°æ®å¤±è´¥: {e}")
            self.request_stats = []
    
    def clear_history(self) -> None:
        """æ¸…ç©ºèŠå¤©å†å²"""
        self.history_manager.clear_history()
        self.logger.info("èŠå¤©å†å²å·²æ¸…ç©º")
    
    def clear_stats(self) -> None:
        """æ¸…ç©ºç»Ÿè®¡æ•°æ®"""
        self.request_stats = []
        self.save_stats()
        self.logger.info("ç»Ÿè®¡æ•°æ®å·²æ¸…ç©º")


async def interactive_chat():
    """äº¤äº’å¼èŠå¤©å‡½æ•°"""
    print("ğŸ¤– OpenAI èŠå¤©å®¢æˆ·ç«¯")
    print("=" * 50)
    print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("è¾“å…¥ 'clear' æ¸…ç©ºå†å²è®°å½•")
    print("è¾“å…¥ 'stats' æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 50)
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAIChatClient()
    
    # æ£€æŸ¥APIå¯†é’¥
    if not client.api_key:
        print("âŒ é”™è¯¯: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return
    
    print(f"âœ… ä½¿ç”¨æ¨¡å‹: {client.model}")
    print(f"ğŸ“š å†å²è®°å½•: {len(client.history_manager.messages)} æ¡æ¶ˆæ¯")
    print()
    
    while True:
        try:
            user_input = input("ğŸ‘¤ æ‚¨: ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ['quit', 'exit']:
                print("ğŸ‘‹ å†è§!")
                break
            
            if user_input.lower() == 'clear':
                client.clear_history()
                print("ğŸ—‘ï¸ å†å²è®°å½•å·²æ¸…ç©º")
                continue
            
            if user_input.lower() == 'stats':
                stats = client.get_stats_summary()
                print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
                for key, value in stats.items():
                    print(f"  {key}: {value}")
                print()
                continue
            
            # å‘é€è¯·æ±‚å¹¶è®¡æ—¶
            start_time = time.time()
            print("ğŸ¤” æ€è€ƒä¸­...")
            
            response = await client.chat(user_input)
            
            end_time = time.time()
            duration = end_time - start_time
            
            print(f"ğŸ¤– AI ({duration:.2f}s): {response}")
            print()
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§!")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            print()


async def main():
    """ä¸»å‡½æ•°"""
    await interactive_chat()


if __name__ == "__main__":
    asyncio.run(main())